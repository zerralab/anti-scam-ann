from typing import Dict, Any, List, Tuple
import re
from fastapi import APIRouter

'''
1. APIç”¨é€”ï¼šé‚è¼¯é”é¢¨æ ¼å’Œåƒ¹å€¼è§€éæ¿¾å™¨ï¼Œèª¿æ•´AIå›æ‡‰çš„èªæ°£å’Œå…§å®¹ä»¥ç¬¦åˆé˜²è©å°å®‰çš„äººè¨­
2. é—œè¯é é¢ï¼šç„¡ç›´æ¥é—œè¯é é¢ï¼Œç‚ºå¾Œå°AIå°è©±åŠŸèƒ½æä¾›èªæ°£èª¿æ•´
3. ç›®å‰ç‹€æ…‹ï¼šå•Ÿç”¨ä¸­ï¼Œç”¨æ–¼æœ¬åœ°è™•ç†AIå›æ‡‰çš„èªæ°£å’Œé•·åº¦
'''

# å»ºç«‹ä¸€å€‹ç©ºçš„ router ä»¥ç¬¦åˆ API æ¨¡çµ„è¦æ±‚
router = APIRouter(
    tags=["values-filter"],
    responses={404: {"description": "Not found"}},
)

# åƒ¹å€¼è§€å®ˆå‰‡èˆ‡æºé€šæ–¹é‡
VALUE_PRINCIPLES = [
    # ç°¡æ½”æ€§åŸå‰‡
    {
        "id": "brevity",
        "check": lambda response, message: check_response_length(response, message),
        "fix": lambda response, message: shorten_response(response)
    },
    # äº’å‹•æ€§åŸå‰‡
    {
        "id": "interactivity",
        "check": lambda response, message: check_interaction_pattern(response),
        "fix": lambda response, message: add_interaction(response)
    },
    # æº«æŸ”èªªæœåŸå‰‡
    {
        "id": "gentle_persuasion",
        "check": lambda response, message: True,  # ç›´æ¥å¥—ç”¨æº«æŸ”èªªæœåŸå‰‡
        "fix": lambda response, message: make_tone_gentler(response)
    },
    # è¬™å‘èªæ°£åŸå‰‡
    {
        "id": "humility",
        "check": lambda response, message: check_humble_tone(response),
        "fix": lambda response, message: remove_condescending_phrases(response)
    },
    # å¹³ç­‰å¹³è¦–åŸå‰‡
    {
        "id": "equality",
        "check": lambda response, message: check_equality_perspective(response),
        "fix": lambda response, message: improve_equality_perspective(response)
    },
    # é«˜ä¸­ç”Ÿèº«ä»½åŸå‰‡
    {
        "id": "high_school_identity",
        "check": lambda response, message: check_high_school_knowledge(response),
        "fix": lambda response, message: adjust_to_high_school_level(response)
    }
]

# æª¢æŸ¥å›æ‡‰æ˜¯å¦éé•· (èˆ‡å•é¡Œè¤‡é›œåº¦ä¸æˆæ¯”ä¾‹)
def check_response_length(response: str, user_message: str) -> bool:
    # è¨ˆç®—æ®µè½æ•¸
    paragraphs = [p for p in response.split('\n') if p.strip()]
    
    # è¨ˆç®—ç”¨æˆ¶å•é¡Œå­—æ•¸
    user_message_length = len(user_message)
    
    # è¨ˆç®—å›æ‡‰å­—æ•¸
    response_length = len(response)
    
    # ç°¡å–®å•é¡Œèªå®šæ¨™æº– (å°æ–¼50å­—)
    is_simple_question = user_message_length < 50
    
    # å¦‚æœæ˜¯ç°¡å–®å•é¡Œä½†å›æ‡‰éé•·æˆ–æ®µè½éå¤š
    if is_simple_question and (response_length > 150 or len(paragraphs) > 2):
        return False
    
    # ä¸€èˆ¬å•é¡Œæ®µè½æ•¸æ‡‰åˆç†æ§åˆ¶
    if len(paragraphs) > 3:
        return False
    
    return True

# ç¸®çŸ­éé•·å›æ‡‰
def shorten_response(response: str) -> str:
    # åˆ†æ®µ
    paragraphs = [p for p in response.split('\n') if p.strip()]
    
    # å¦‚æœæ®µè½éå¤šï¼Œåªä¿ç•™å‰2å€‹æ®µè½
    if len(paragraphs) > 2:
        shortened = '\n'.join(paragraphs[:2])
        
        # ç¢ºä¿çµå°¾æœ‰è¡¨æƒ…ç¬¦è™Ÿ
        if not any(emoji in shortened[-5:] for emoji in ['ğŸ˜Š', 'ğŸ¤—', 'ğŸ‘', 'ğŸ’ª', 'ğŸ˜‰']):
            shortened = shortened + 'ğŸ˜Š'
            
        return shortened
    
    # å¦‚æœå­—æ•¸éå¤šä½†æ®µè½å°‘ï¼Œå˜—è©¦ç°¡åŒ–å¥å­
    if len(response) > 150 and len(paragraphs) <= 2:
        # æ‰¾åˆ°ç¬¬ä¸€å€‹å¥è™Ÿæˆ–å•è™Ÿè™•æˆªæ–·
        for punct_pos in [pos for pos, char in enumerate(response) if char in ['ã€‚', 'ï¼Ÿ', 'ï¼'] and pos > 80]:
            if punct_pos < len(response) - 1:
                shortened = response[:punct_pos+1]
                
                # ç¢ºä¿çµå°¾æœ‰è¡¨æƒ…ç¬¦è™Ÿ
                if not any(emoji in shortened[-5:] for emoji in ['ğŸ˜Š', 'ğŸ¤—', 'ğŸ‘', 'ğŸ’ª', 'ğŸ˜‰']):
                    shortened = shortened + 'ğŸ˜Š'
                    
                return shortened
    
    return response

# æª¢æŸ¥æ˜¯å¦æœ‰äº’å‹•æ¨¡å¼ (å•å¥çµå°¾)
def check_interaction_pattern(response: str) -> bool:
    # æª¢æŸ¥çµå°¾æ˜¯å¦åŒ…å«å•å¥
    last_sentences = response.split('ã€‚')[-2:]
    last_text = 'ã€‚'.join(last_sentences)
    
    # æª¢æŸ¥æœ«å°¾æ˜¯å¦æœ‰å•è™Ÿæˆ–é‚€è«‹æ€§è©èª
    return 'ï¼Ÿ' in last_text or any(phrase in last_text for phrase in ['å¦‚ä½•', 'ä»€éº¼', 'è¦ä¸è¦', 'æƒ³ä¸æƒ³', 'å¯ä»¥å—'])

# æ·»åŠ äº’å‹•æ€§å•å¥
def add_interaction(response: str) -> str:
    # å¦‚æœçµå°¾æ²’æœ‰å•å¥ï¼Œæ·»åŠ ä¸€å€‹äº’å‹•æ€§å•é¡Œ
    if not response.rstrip().endswith('ï¼Ÿ'):
        # ç§»é™¤å°¾éƒ¨è¡¨æƒ…ç¬¦è™Ÿï¼ˆå¦‚æœæœ‰ï¼‰
        emoji_pattern = re.compile(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F700-\U0001F77F\U0001F780-\U0001F7FF\U0001F800-\U0001F8FF\U0001F900-\U0001F9FF\U0001FA00-\U0001FA6F\U0001FA70-\U0001FAFF\U00002702-\U000027B0\U000024C2-\U0001F251\U0001f926-\U0001f937]+')
        clean_response = emoji_pattern.sub('', response.rstrip())
        
        # ä¾æ“šå›æ‡‰å…§å®¹é¸æ“‡é©åˆçš„äº’å‹•å•å¥
        interaction_questions = [
            'ä½ è¦ºå¾—é€™æ¨£å¯ä»¥å—ï¼Ÿ',
            'ä½ æœ‰ä»€éº¼æƒ³æ³•å‘¢ï¼Ÿ',
            'é€™å°ä½ æœ‰å¹«åŠ©å—ï¼Ÿ',
            'ä½ é‡åˆ°é¡ä¼¼çš„æƒ…æ³å—ï¼Ÿ'
        ]
        
        # é¸æ“‡ä¸€å€‹å•å¥
        import random
        question = random.choice(interaction_questions)
        
        # æ·»åŠ åˆ°å›æ‡‰æœ«å°¾
        return f"{clean_response}\n\n{question}ğŸ˜Š"
    
    return response

# æª¢æŸ¥æ˜¯å¦æœ‰å±…é«˜è‡¨ä¸‹çš„èªæ°£
def check_humble_tone(response: str) -> bool:
    # æª¢æŸ¥æ˜¯å¦åŒ…å«å±…é«˜è‡¨ä¸‹çš„è©èª
    condescending_phrases = [
        "å…¶å¯¦", "è€å¯¦èªª", "èªªå¯¦è©±", "è¬›çœŸçš„", "å•Š", "è¦çŸ¥é“", "ä½ æ‡‰è©²", "ä½ å¿…é ˆ", 
        "æ‡‰è©²å¼•èµ·è­¦æƒ•", "ç‚ºä»€éº¼ä¸æ˜¯å¤§å®¶éƒ½åœ¨åš", "ç‚ºä»€éº¼ä¸æ˜¯", "æ‡‰è©²æ„è­˜åˆ°",
        "æˆ‘å¿…é ˆèª å¯¦", "ä½ è¦å°å¿ƒ", "ä¸€å®šè¦", "ä¸èƒ½", "å³ä½¿", "ä¸æ‡‰è©²", "æƒ³æ¸…æ¥š"
    ]
    return not any(phrase in response for phrase in condescending_phrases)

# ç§»é™¤å±…é«˜è‡¨ä¸‹çš„è©èª
def remove_condescending_phrases(response: str) -> str:
    # æ›¿æ›å±…é«˜è‡¨ä¸‹çš„è©èªç‚ºæ›´æº«å’Œçš„è¡¨é”
    replacements = {
        "å…¶å¯¦": "èˆ‡ä½ åˆ†äº«",
        "è€å¯¦èªª": "æˆ‘è¦ºå¾—",
        "èªªå¯¦è©±": "æˆ‘æœ‰é»æ“”å¿ƒ",
        "è¬›çœŸçš„": "æˆ‘å€‘ä¸€èµ·æƒ³æƒ³",
        "å•Š": "",
        "è¦çŸ¥é“": "ä¹Ÿè¨±",
        "ä½ æ‡‰è©²": "ä¹Ÿè¨±å¯ä»¥è€ƒæ…®",
        "ä½ å¿…é ˆ": "æˆ‘å€‘å¯ä»¥ä¸€èµ·",
        "æ‡‰è©²å¼•èµ·è­¦æƒ•": "æˆ‘æœ‰é»æ“”å¿ƒ",
        "ç‚ºä»€éº¼ä¸æ˜¯å¤§å®¶éƒ½åœ¨åš": "å¦‚æœæœ‰é€™éº¼å¥½çš„æ©Ÿæœƒï¼Œå¤šå’Œä¿¡ä»»çš„äººè¨è«–çœ‹çœ‹",
        "ç‚ºä»€éº¼ä¸æ˜¯": "ä¹Ÿè¨±å¯ä»¥å†äº†è§£çœ‹çœ‹",
        "æ‡‰è©²æ„è­˜åˆ°": "æˆ‘å€‘å¯ä»¥ä¸€èµ·é—œæ³¨",
        "æˆ‘å¿…é ˆèª å¯¦": "æˆ‘æœ‰é»æ“”å¿ƒ",
        "ä½ è¦å°å¿ƒ": "å¯èƒ½è¦å¤šæƒ³æƒ³",
        "ä¸€å®šè¦": "å¯èƒ½æ¯”è¼ƒå¥½",
        "ä¸èƒ½": "ä¹Ÿè¨±ä¸å¤ªå»ºè­°",
        "å³ä½¿": "å°±ç®—",
        "ä¸æ‡‰è©²": "æˆ‘æœƒè€ƒæ…®å†",
        "æƒ³æ¸…æ¥š": "å¯ä»¥å†æƒ³æƒ³"
    }
    
    for phrase, replacement in replacements.items():
        response = response.replace(phrase, replacement)
    
    return response

# æª¢æŸ¥æ˜¯å¦å¹³ç­‰å¹³è¦–çš„è¦–è§’
def check_equality_perspective(response: str) -> bool:
    # æª¢æŸ¥æ˜¯å¦ä½¿ç”¨å¹³ç­‰å…±å‰µçš„è¡¨é”æ–¹å¼
    equality_phrases = ["ä¸€èµ·", "æˆ‘å€‘å¯ä»¥", "ä½ è¦ºå¾—", "ä½ æƒ³", "è¬è¬ä½ "]
    return any(phrase in response for phrase in equality_phrases)

# æ”¹å–„å¹³ç­‰å¹³è¦–çš„è¦–è§’
def improve_equality_perspective(response: str) -> str:
    # åˆ†ææ˜¯å¦éœ€è¦æ·»åŠ å¹³ç­‰è¡¨é”è©èª
    if not any(phrase in response for phrase in ["ä¸€èµ·", "æˆ‘å€‘", "ä½ è¦ºå¾—", "å¦‚æœä½ æƒ³", "ä¹Ÿè¨±æˆ‘å€‘", "èˆ‡ä½ åˆ†äº«"]):
        # æ‰¾åˆ°é©åˆæ’å…¥å¹³ç­‰è¦–è§’è©èªçš„ä½ç½®
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', response)
        if len(sentences) > 1:
            modified_sentences = []
            inserted = False
            
            for i, sentence in enumerate(sentences):
                if i == 1 and not inserted and sentence.strip():
                    # åœ¨ç¬¬äºŒå¥å‰æ·»åŠ å¹³ç­‰è¦–è§’è©èª
                    equality_phrases = [
                        "æˆ‘å€‘å¯ä»¥ä¸€èµ·æƒ³æƒ³", 
                        "è·Ÿä½ åˆ†äº«æˆ‘çš„æƒ³æ³•ï¼Œ", 
                        "ä¹Ÿè¨±æˆ‘å€‘å¯ä»¥é€™æ¨£çœ‹ï¼Œ", 
                        "ä¸çŸ¥é“ä½ è¦ºå¾—å¦‚ä½•ï¼Œ", 
                        "å¸Œæœ›èƒ½è·Ÿä½ ä¸€èµ·æƒ³æƒ³ï¼Œ"
                    ]
                    import random
                    prefix = random.choice(equality_phrases)
                    modified_sentences.append(f"{prefix}{sentence}")
                    inserted = True
                else:
                    modified_sentences.append(sentence)
            
            # é‡æ–°çµ„åˆå¥å­
            result = ''
            for i, s in enumerate(modified_sentences):
                if i < len(modified_sentences) - 1:
                    # å¦‚æœå¥å­ä¸æ˜¯ä»¥æ¨™é»ç¬¦è™Ÿçµå°¾ï¼Œæ·»åŠ å¥è™Ÿ
                    if s and s[-1] not in 'ã€‚ï¼ï¼Ÿ':
                        result += s + 'ã€‚'
                    else:
                        result += s
                else:
                    result += s
            
            return result
    
    return response

# æª¢æŸ¥æ˜¯å¦ç¬¦åˆé«˜ä¸­ç”ŸçŸ¥è­˜æ°´å¹³
def check_high_school_knowledge(response: str) -> bool:
    # æª¢æŸ¥æ˜¯å¦ä½¿ç”¨éæ–¼å°ˆæ¥­æˆ–æ·±å¥§çš„è©å½™
    expert_phrases = ["æ ¹æ“šç ”ç©¶", "ç§‘å­¸è­‰æ˜", "çµ±è¨ˆæ•¸æ“šè¡¨æ˜", "å°ˆæ¥­è§’åº¦", "ä¾æ“šç¶“é©—"]
    return not any(phrase in response for phrase in expert_phrases)

# èª¿æ•´ç‚ºé«˜ä¸­ç”ŸçŸ¥è­˜æ°´å¹³
def adjust_to_high_school_level(response: str) -> str:
    # æ›¿æ›éæ–¼å°ˆæ¥­çš„è¡¨è¿°
    replacements = {
        "æ ¹æ“šç ”ç©¶": "æˆ‘è½èªª",
        "ç§‘å­¸è­‰æ˜": "å¥½åƒæ˜¯",
        "çµ±è¨ˆæ•¸æ“šè¡¨æ˜": "é€šå¸¸ä¾†èªª",
        "å°ˆæ¥­è§’åº¦": "æˆ‘çš„æƒ³æ³•",
        "ä¾æ“šç¶“é©—": "å¾æˆ‘äº†è§£çš„"
    }
    
    for phrase, replacement in replacements.items():
        response = response.replace(phrase, replacement)
    
    return response

# èª¿æ•´ç‚ºæº«æŸ”èªªæœçš„èªæ°£
def make_tone_gentler(response: str) -> str:
    """ç¢ºä¿èªæ°£æº«æŸ”ä½†æœ‰æ•ˆèªªæœï¼Œé¿å…è³ªå•æˆ–å’„å’„é€¼äººçš„èªæ°£"""
    
    # è³ªå•æ€§è¡¨é”è½‰æ›æˆæº«å’Œå»ºè­°
    question_replacements = {
        "ç‚ºä»€éº¼ä¸": "ä¹Ÿè¨±å¯ä»¥å†è€ƒæ…®",
        "æ€éº¼å¯èƒ½": "æˆ‘æœ‰é»æ“”å¿ƒ",
        "ä½ æ‡‰è©²çŸ¥é“": "æˆ‘å€‘å¯ä»¥çŸ¥é“",
        "ä½ ä¸è¦ºå¾—å—": "æˆ‘è¦ºå¾—",
        "ä½ æ€éº¼æœƒ": "æˆ‘æœ‰é»å¥½å¥‡",
        "é›£é“ä½ ä¸": "ä¹Ÿè¨±æˆ‘å€‘å¯ä»¥",
        "è‹¥çœŸå¦‚æ­¤": "å¦‚æœæ˜¯é€™æ¨£"
    }
    
    # åµæ¸¬å…ˆåˆ¤æ–·å¾Œèªªæœçš„å¥å‹
    if "é€™æ˜¯è©é¨™" in response or "é€™çœ‹èµ·ä¾†å¾ˆåƒè©é¨™" in response:
        # æ”¹æˆã€Œæˆ‘æœ‰é»æ“”å¿ƒã€çš„è¡¨é”
        response = response.replace("é€™æ˜¯è©é¨™", "æˆ‘æœ‰é»æ“”å¿ƒé€™å¯èƒ½æ˜¯è©é¨™")
        response = response.replace("é€™çœ‹èµ·ä¾†å¾ˆåƒè©é¨™", "é€™æ¨£çš„è¨Šæ¯æœ‰é»è®“æˆ‘æ“”å¿ƒ")
    
    # æ‡‰ç”¨æº«æŸ”è¡¨é”è½‰æ›
    for phrase, replacement in question_replacements.items():
        response = response.replace(phrase, replacement)
    
    # ç¢ºä¿èªæ°£å‹å–„ä½†ä¸å¤±å»ä½œç”¨
    if "å°å¿ƒ" in response and "æ“”å¿ƒ" not in response:
        response = response.replace("å°å¿ƒ", "å¤šæ³¨æ„")
    
    # ç¢ºä¿ä¸æœƒé‡è¤‡ä½¿ç”¨ã€Œæ“”å¿ƒã€è©èª
    if response.count("æ“”å¿ƒ") > 1:
        response = response.replace("æ“”å¿ƒ", "åœ¨æ„", 1)
    
    return response

# ä¸»è¦åŠŸèƒ½ï¼šæ‡‰ç”¨åƒ¹å€¼è§€æª¢æŸ¥ä¸¦èª¿æ•´å›æ‡‰
def ensure_meaningful_response(response: str, original_response: str) -> str:
    """
    ç¢ºä¿å›æ‡‰æœ‰æ„ç¾©ä¸”ç¬¦åˆå°å®‰çš„åŠ©äººç²¾ç¥
    å¦‚æœæ”¹å¯«å¾Œçš„å›æ‡‰è®Šå¾—ç„¡æ„ç¾©ï¼Œå‰‡æ¢å¾©ä½¿ç”¨åŸå§‹å›æ‡‰
    
    Args:
        response: ç¶“éåƒ¹å€¼è§€è™•ç†å¾Œçš„å›æ‡‰
        original_response: åŸå§‹AIç”Ÿæˆçš„å›æ‡‰
        
    Returns:
        ç¢ºä¿æœ‰æ„ç¾©çš„å›æ‡‰
    """
    # æª¢æŸ¥å›æ‡‰æ˜¯å¦å¹¾ä¹åªæœ‰æ¨™é»ç¬¦è™Ÿæˆ–ç©ºç™½
    if re.match(r'^[\s\.,ï¼Œã€‚ã€ï¼Ÿï¼""â€¦]{0,20}$', response):
        # å¦‚æœåŸå§‹å›æ‡‰ä¹Ÿæœ‰å•é¡Œï¼Œæä¾›é»˜èªå›æ‡‰
        if not original_response or len(original_response.strip()) < 30:
            return "å“å‘€ï¼Œé€™å€‹å•é¡Œè®“æˆ‘æƒ³äº†ä¸€ä¸‹ã€‚å¯ä»¥å†å‘Šè¨´æˆ‘å¤šä¸€äº›ç´°ç¯€å—ï¼Ÿé€™æ¨£æˆ‘èƒ½æ›´å¥½åœ°å¹«åŠ©ä½ ã€‚ğŸ˜Š"
        
        # å¦‚æœåŸå§‹å›æ‡‰æœ‰å¯¦è³ªå…§å®¹ï¼Œå‰‡ä½¿ç”¨åŸå§‹å›æ‡‰
        return original_response
    
    # æª¢æŸ¥æ˜¯å¦éåº¦ç°¡åŒ–ï¼ˆå…§å®¹æ¸›å°‘è¶…é70%ï¼‰
    if len(response) < len(original_response) * 0.3 and len(original_response) > 100:
        # å˜—è©¦ä¿ç•™åŸå§‹å›æ‡‰çš„ä¸»è¦éƒ¨åˆ†ï¼Œä½†èª¿æ•´èªæ°£
        modified_original = make_tone_gentler(original_response)
        return modified_original
    
    return response

def apply_values_filter(response: str, user_message: str) -> Tuple[str, List[str]]:
    """
    æ‡‰ç”¨åƒ¹å€¼è§€ç·¨è¼¯ä¸¦èª¿æ•´å›æ‡‰ï¼Œè¿”å›èª¿æ•´å¾Œçš„å›æ‡‰å’Œæ‡‰ç”¨çš„åŸå‰‡åˆ—è¡¨
    
    Args:
        response: åŸå§‹AIå›æ‡‰
        user_message: ç”¨æˆ¶è¨Šæ¯
        
    Returns:
        Tuple(èª¿æ•´å¾Œçš„å›æ‡‰, æ‡‰ç”¨çš„åŸå‰‡åˆ—è¡¨)
    """
    original_response = response
    modified_response = response
    applied_principles = []
    
    # æ‡‰ç”¨æ¯å€‹åƒ¹å€¼è§€åŸå‰‡ï¼Œä½†æ›´è¬¹æ…åœ°ä¿ç•™å…§å®¹
    for principle in VALUE_PRINCIPLES:
        # æª¢æŸ¥æ˜¯å¦ç¬¦åˆåŸå‰‡
        if not principle["check"](modified_response, user_message):
            # æ‡‰ç”¨ä¿®å¾©
            old_response = modified_response
            modified_response = principle["fix"](modified_response, user_message)
            
            # æª¢æŸ¥æ˜¯å¦æœ‰è®ŠåŒ–
            if old_response != modified_response:
                applied_principles.append(principle["id"])
    
    # æœ€çµ‚ç¢ºä¿å›æ‡‰æœ‰æ„ç¾©
    final_response = ensure_meaningful_response(modified_response, original_response)
    
    # å¦‚æœæœ€çµ‚å›æ‡‰èˆ‡ä¿®æ”¹å¾Œå›æ‡‰ä¸åŒï¼Œæ·»åŠ å®‰å…¨æª¢æŸ¥åŸå‰‡
    if final_response != modified_response:
        applied_principles.append("safety_check")
    
    return final_response, applied_principles
